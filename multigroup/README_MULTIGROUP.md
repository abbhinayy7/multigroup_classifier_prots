# MultiGroup ProteoBoostR - Files & Documentation Overview

## ðŸ“¦ Complete Package Contents

### Executable Scripts

#### 1. `RUN_ALL_TASKS.ps1` (Windows PowerShell)
- **Purpose:** Execute the complete workflow automatically
- **Usage:** 
  ```powershell
  cd f:\ProteoBoostR\multigroup
  .\RUN_ALL_TASKS.ps1
  ```
- **What it does:**
  1. Generates synthetic multiclass test data
  2. Trains model on synthetic data (Bayesian optimization + XGBoost)
  3. Evaluates with One-vs-Rest (OVR) ROC
  4. Evaluates with One-vs-One (OVO) pairwise ROC
  5. Makes predictions on independent data (ad-hoc apply)
  6. (BONUS) Trains on real GBM CPTAC data and applies to Werner dataset

#### 2. `run_all_tasks.sh` (Bash/Shell - Linux/Mac)
- **Purpose:** Same as PowerShell version, for Unix-like systems
- **Usage:**
  ```bash
  cd /path/to/ProteoBoostR/multigroup
  bash run_all_tasks.sh
  ```

---

### Python CLI

#### 3. `py_scripts/cli.py`
- **Purpose:** Main command-line interface for all operations
- **Subcommands:**
  - `train` â€” Build multiclass XGBoost model with hyperparameter optimization
  - `evaluate` â€” Assess model performance (OVR or OVO ROC)
  - `apply` â€” Make predictions on new data
- **Key Features:**
  - Bayesian optimization for hyperparameter tuning (8 parameters)
  - Multiclass support (2+ classes)
  - One-vs-Rest and One-vs-One ROC analysis
  - Stratified train/test split
  - Adaptive cross-validation folds

#### 4. `py_scripts/utils.py`
- **Purpose:** Utility functions for data handling
- **Functions:**
  - `read_annotation()` â€” Load annotation TSV
  - `read_protein()` â€” Load protein TSV
  - `merge_annot_prot()` â€” Merge annotation and protein data on sample_id
  - `preprocess_multiclass()` â€” Label encode, handle missing values
  - `resolve_output_dir()` â€” Create output directory if needed
  - `write_tsv()` â€” Save TSV files
  - `safe_timestamp()` â€” Generate timestamp for versioning

---

### Documentation & Guides

#### 5. `WORKFLOW_GUIDE.md` (Comprehensive)
- **What to read:** For detailed understanding of the pipeline
- **Contains:**
  - Overview of the workflow (5 main steps)
  - Detailed command explanations with parameter tables
  - Data format requirements with examples
  - Output file descriptions
  - Typical workflow examples
  - Tips & best practices
  - Troubleshooting guide
- **Best for:** Understanding what each command does and why

#### 6. `QUICK_REFERENCE.md` (Cheat Sheet)
- **What to read:** For quick copy-paste commands
- **Contains:**
  - Fastest ways to get started (one-liners)
  - Copy-paste examples for all 4 operations
  - Parameter guide (compact table)
  - Expected input file formats
  - Output files listing
  - Quick examples for common scenarios
  - Tuning tips table
  - Troubleshooting quick reference
- **Best for:** Finding the command you need right now

#### 7. `README_MULTIGROUP.md` (This file - Overview)
- **What to read:** For high-level overview
- **Contains:** File listing, quick start, what each document is for

---

### Test Data & Examples

#### 8. `test_data/annotation.tsv`
- **Purpose:** Example annotation file (multiclass labels)
- **Format:** TSV with `sample_id` and `label` columns
- **Generated by:** `generate_synthetic.py`

#### 9. `test_data/protein.tsv`
- **Purpose:** Example protein data (feature matrix)
- **Format:** TSV with proteins as rows, samples as columns
- **Generated by:** `generate_synthetic.py`

#### 10. `test_data/generate_synthetic.py`
- **Purpose:** Create synthetic test dataset
- **Usage:**
  ```bash
  python test_data/generate_synthetic.py
  ```
- **Creates:** 120 samples, 200 proteins, 3 classes (Control, GroupA, GroupB)

---

### Output Directories (Generated During Runs)

#### 11. `test_output/` (Synthetic data results)
- **Contents after train:** Models, matrices, parameters
- **Contents after evaluate:** ROC plots, metrics, confusion matrix
- **Contents after apply:** Predictions, confidence plots

#### 12. `../GBM_testcase/multigroup_output/` (Real data results)
- **Location:** GBM test case directory
- **Contents:** Same as test_output but for real GBM CPTAC data
- **Includes:** Evaluation on 3 real classes (nmf1, nmf2, nmf3)

---

## ðŸš€ How to Use This Package

### Step 1: Choose Your Starting Point

**Option A - Fastest (5 minutes):**
```powershell
.\RUN_ALL_TASKS.ps1
```
Runs everything automatically. Best for seeing how the pipeline works.

**Option B - Manual Control (Flexible):**
Follow commands in `QUICK_REFERENCE.md`. Best for custom data or understanding each step.

**Option C - Deep Dive (Learning):**
Read `WORKFLOW_GUIDE.md` first, then run commands. Best for understanding the science.

---

### Step 2: Run Commands

**Train:**
```bash
python py_scripts/cli.py train \
  --annotation test_data/annotation.tsv \
  --protein test_data/protein.tsv \
  --annotcol label \
  --output test_output \
  --n_iter 3 --init_points 2
```

**Evaluate (OVR):**
```bash
python py_scripts/cli.py evaluate \
  --model test_output/xgb_model_<timestamp>.joblib \
  --annotation test_data/annotation.tsv \
  --protein test_data/protein.tsv \
  --annotcol label \
  --output test_output \
  --roc_mode ovr
```

**Evaluate (OVO):**
```bash
python py_scripts/cli.py evaluate \
  --model test_output/xgb_model_<timestamp>.joblib \
  --annotation test_data/annotation.tsv \
  --protein test_data/protein.tsv \
  --annotcol label \
  --output test_output \
  --roc_mode ovo
```

**Apply:**
```bash
python py_scripts/cli.py apply \
  --model test_output/xgb_model_<timestamp>.joblib \
  --protein test_data/protein.tsv \
  --annotation test_data/annotation.tsv \
  --annotcol label \
  --output test_output
```

---

### Step 3: Review Results

Check `test_output/` or `../GBM_testcase/multigroup_output/` for:
- `roc_curve_*.png` â€” One-vs-Rest ROC plot
- `roc_pair_*_vs_*.png` â€” Pairwise ROC plots (OVO mode)
- `evaluation_report_*.tsv` â€” Per-class metrics
- `pairwise_aucs_*.tsv` â€” Pairwise AUC summary
- `confusion_matrix_*.tsv` â€” Classification matrix
- `predicted_samples_*.png` â€” Ranked prediction plot

---

## ðŸ“š Document Quick Links

| Document | Purpose | Best For |
|----------|---------|----------|
| `RUN_ALL_TASKS.ps1` | Run everything | Quick demo, end-to-end testing |
| `QUICK_REFERENCE.md` | Copy-paste commands | Finding the command you need |
| `WORKFLOW_GUIDE.md` | Detailed explanations | Understanding the pipeline |
| `py_scripts/cli.py` | Main program | Implementation details |
| `py_scripts/utils.py` | Utilities | Data handling code |

---

## ðŸŽ¯ Example Scenarios

### Scenario 1: Test Synthetic Data Pipeline
```bash
# Everything in one script
.\RUN_ALL_TASKS.ps1
# Output: test_output/ contains models + metrics + plots
```

### Scenario 2: Train on Your Own Data
```bash
python py_scripts/cli.py train \
  --annotation YOUR_ANNOTATION.tsv \
  --protein YOUR_PROTEIN.tsv \
  --annotcol YOUR_LABEL_COLUMN \
  --output my_results \
  --n_iter 25 --init_points 5
```

### Scenario 3: Cross-Dataset Evaluation
```bash
# Train on Dataset A
python py_scripts/cli.py train \
  --annotation dataset_a_annot.tsv \
  --protein dataset_a_proteins.tsv \
  --annotcol diagnosis \
  --output results

# Apply to Dataset B
python py_scripts/cli.py apply \
  --model results/xgb_model_*.joblib \
  --protein dataset_b_proteins.tsv \
  --annotation dataset_b_annot.tsv \
  --annotcol diagnosis \
  --output results
```

### Scenario 4: Compare ROC Modes
```bash
# OVR evaluation
python py_scripts/cli.py evaluate \
  --model results/xgb_model_*.joblib \
  --annotation data_annot.tsv \
  --protein data_proteins.tsv \
  --annotcol label \
  --output results \
  --roc_mode ovr

# OVO evaluation
python py_scripts/cli.py evaluate \
  --model results/xgb_model_*.joblib \
  --annotation data_annot.tsv \
  --protein data_proteins.tsv \
  --annotcol label \
  --output results \
  --roc_mode ovo

# Both ROC curves + pairwise AUCs now in results/
```

---

## ðŸ“‹ Hyperparameter Explanation

The model optimizes these 8 parameters via Bayesian Optimization:

1. **learning_rate (eta):** 0.001-0.5
   - Lower = slower learning, more boosting needed
   - Higher = faster convergence but risk overfitting

2. **max_depth:** 2-12
   - Tree depth; higher = more complex trees

3. **subsample:** 0.4-1.0
   - Fraction of samples per tree; helps prevent overfitting

4. **colsample_bytree:** 0.3-1.0
   - Fraction of features per tree

5. **min_child_weight:** 1-10
   - Minimum sum of weights in child node

6. **gamma:** 0.0-5.0
   - Loss reduction required for split

7. **reg_alpha:** 0.0-10.0
   - L1 regularization (encourages sparsity)

8. **reg_lambda:** 0.0-10.0
   - L2 regularization (discourages large weights)

**Optimization Goal:** Maximize `f1_macro` (macro-averaged F1 score) via 5-fold cross-validation on training set.

---

## âœ¨ Key Features

âœ… **Multiclass Support** â€” 2+ classes (not limited to binary)
âœ… **Hyperparameter Optimization** â€” Bayesian search for 8 parameters
âœ… **Two ROC Modes** â€” One-vs-Rest (OVR) and One-vs-One (OVO) pairwise
âœ… **Cross-Dataset** â€” Train on one dataset, apply to another
âœ… **Stratified Split** â€” Maintains class proportions in train/test
âœ… **Adaptive CV Folds** â€” Adjusts to class size automatically
âœ… **Rich Outputs** â€” Models, metrics, visualizations, predictions
âœ… **Publication-Quality Plots** â€” High-resolution (150 DPI) PNG figures
âœ… **Reproducible** â€” Seed control for deterministic results
âœ… **Windows + Unix** â€” PowerShell + Bash scripts included

---

## ðŸ”§ Requirements

**Python 3.7+** with packages:
- xgboost
- scikit-learn
- pandas
- numpy
- matplotlib
- bayesian-optimization (bayes_opt)
- joblib

Install via:
```bash
pip install xgboost scikit-learn pandas numpy matplotlib bayesian-optimization joblib
```

---

## ðŸ“ž Quick Help

**Forgot a command?** â†’ See `QUICK_REFERENCE.md`

**Want to understand how it works?** â†’ Read `WORKFLOW_GUIDE.md`

**Want to run everything?** â†’ Execute `RUN_ALL_TASKS.ps1` (Windows) or `run_all_tasks.sh` (Unix)

**Have a question about a parameter?** â†’ Check parameter table in `WORKFLOW_GUIDE.md`

---

## ðŸŽ“ Next Steps

1. Run `RUN_ALL_TASKS.ps1` to see the pipeline in action
2. Read `QUICK_REFERENCE.md` for available commands
3. Prepare your own annotation + protein TSV files
4. Use `QUICK_REFERENCE.md` to build your custom command
5. Review metrics and plots in the output directory

Good luck! ðŸš€

